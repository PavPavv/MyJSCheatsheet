# Алгоритмы. Теория

(Материал взят из [лекций Яндекса на youtube](https://www.youtube.com/watch?v=QLhqYNsPIVo&list=PL6Wui14DvQPySdPv5NUqV3i8sDbHkCKC5) и русского издания книги Джорджа Хайнемана "Алгоритмы с примерами на Python")

## Основные базовые темы

- Некоторые концепции computer science
- Сложность алгоритмов
- Линейный поиск
- Множества
- Словари, сортировка подсчетом
- Префиксные суммы, два указателя
- Бинарный поиск

### Некоторые концепции computer science

Главное **отличие машинного кода от байт-кода** в том, что машинный код содержит инструкции процессора, которые работают с тем, что на самом деле есть в процессоре: атомарными ячейками памяти, их адресами и регистрами, а байт-код - это инструкции программы-интерпретатора, которые, по сути, отличаются от языка программирова­ния только представлением - в них используются имена, объектная модель, составные типы данных и все остальное.

**Массив** -фиксированный набор однотипных значений, занимающий один непрерывный фрагмент оперативной памяти. Это одна из самых старых и самых надежных структур данных. Если значений больше одного - программисты хранят их в массиве.

Почему **кастомная функция все равно работает медленнее встроенного метода**? Дело в том, что Python - интер­претируемый язык программирования : написанная программа транслируется в промежуточное представление, называемое байт-кодом, а при выполнении программы запускается интерпретатор Python, который читает, интерпрети­рует и выполняет инструкции байт-кода. Встроенные же функции, например max( ), - часть самого интерпретатора: пока такая функция обрабатывает объ­ект, не нужно ничего дополнительно интерпретировать. Поэтому встроенные функции всегда быстрее тех, чем написанные. Например, что требуется интерпретировать в цикле (то есть многократно) при вы­ полнении кастомной функции? В первую очередь - поиск имен переменных: Python не может быть уверен, что, скажем, idx вообще существует на каждом следующем проходе цикла, ведь это имя вполне могли удалить! Дополнительное время тратится на вычисление выра­жений, ибо для каждого промежуточного результата приходится заводить отдельный объект Python, а затем уничтожать его. Схожая ситуация с операцией индексации и т. д. Встроенная же функция шах() тратит время только на обход конкретного выданного ей списка и на сравнение.

### Сложность алгоритмов

Сложность алгоритма - это то, как будет расти расход ресурсов с увеличением размера входных данных. Под ресурсами понимается время и память.
**Big O** - это функция, которая описывает рост сложности алгоритма. По сути, это график функции алгоритма, который отражает зависимоть использования памяти и времени от колличества исполнения операций. Нотация **Big O** указывает на самую быстрорастущую сложность алгоритма и игнорирует константные оптимизации.
**N** - это колличество переданных для операции элементов.

Предположим, выполнение одной машинной инструкции центральным про­ цессором некоторого компьютера требует фиксированного времени t.
Тогда время Т, затраченное на работу алгоритма на этом компьютере, можно выразить как Т(N) = t х O(N). Cамое важное - это структура программы.

Когда мы исследуем алгоритм, важно установить его сложность по памяти - посчитать, сколько дополнительной памяти требуется на обработку входных данных размером N.
Под памятью может подразумеваться занимаемое место в файловой системе или объем оперативной памяти, который требуется для работы. Cложность по памяти не зависит от размера входных данных, то есть является константой.

В математике для классификации вычислительной сложности алгоритмов (и в худшем, и в лучшем случаях) используется обозначение «O» большое». «0» в данном случае означает order, то есть «порядок». Порядок функции - это скорость, с которой опа растет при росте ее переменной, N. 4N^2 + ЗN - 5 - "порядка N^2", потому что быстрее всего в этом многочлене растет первое слагаемое, в котором степень N равна 2.

Для оценки быстродействия алгоритма па наборе данных размером N обычно начинают считать количество вьшолпеппых им действий. Предполагается, что каждое действие выполняется за фиксировашюе время, что и превращает этот подсчет в оценку предполагаемого времени работы.

T(N) - время, которое потребуется алгоритму для обработки набора данных размером N. Для входных данных из лучшего и худшего случаев могут быть свои, непохожие друг на друга T(N). При этом не имеет значения, в чем измеряется­ время - в секундах или миллисекундах.

S(N) - объем памяти, требуемый для работы алгоритма на наборе данных размером N. Для входных данных из лучшего и худшего случаев могут быть свои, непохожие друг на друга S(N). При этом не имеет значения, в чем из­меряется объем памяти - в битах или гигабайтах.

Если мы подобрали некоторую функцию f/(N), которая оценивает количе­ство действий, выполняемых нашим алгоритмом, тем самым мы автоматически классифицируем сложность этого алгоритма как
O(f/(N)).

Доминирование классов друг над другом выражается еще в том, как определя­ется алгоритм, в оценке сложности которого встречаются несколько различ­ных компонентов-формул. Например, если сложность одной части алгоритма оценивается как O(N log N), а другой - как О(N^2), то какова сложность всего алгоритма? Ответ: О(N^2), потому что сложность второй части доминирует над
сложностью первой.

#### O(1) - постоянная сложность алгоритма

В следующем примере алгоритм вообще ничего не принимает, поэтому никак не зависит от входных данных:

```javascript
function constantComplexity() {
  const a = 1 + 2;
  const b = 3 + 4;

  console.log('calculating...');

  return b - a;
}
```

#### O(n) - линейная сложность алгоритма

Линейная сложность алгоритма(чем больше массив, переданный в качестве аргумента, тем больше итераций по нему) :

```javascript
function linearCompexity(array) {
  let sum = 0;

  array.forEach((number) => (sum += number));

  return sum;
}
```

Сортировка подсчетом. Если известно, что некоторый (произвольный) спи­сок А состоит только из целых чисел в диапазоне от О до М, его можно отсорти­ровать за линейное время, используя дополнительную память размером М.

#### O(n^2) - квадратичная сложность алгоритма

```javascript
function squaredComplexity(array) {
  for (let i = 0; i < array.length; i++) {
    for (let j = 0; j < array.length; j++) {
      array[i] = array[i] + array[j];
    }
  }

  return array;
}
```

Пример оптимизации квадратичной сложности алгоритма:

```javascript
function squaredComplexity(array) {
  let total = 0;

  array.forEach((num) => {
    const additional = array.indexOf(num) > 5 ? 5 : 1;
    // indexOf - реализован тоже с помощью цикла, получаем два вложенных цикла

    total = total + num + additional;
  });

  return array;
}

function becameLinearComplexity(array) {
  let total = 0;

  array.forEach((num, index) => {
    const additional = index > 5 ? 5 : 1;

    total = total + num + additional;
  });

  return array;
}
```

#### Виды сложностей алгоритма по увеличению потрбления памяти и времени (от лучшего к худшему)

1. O(1) - **константная** — 1 (одна) операция;
2. O(log n) - **логарифмическая** (например, бинарный поиск) — ~13 (чуть более тринадцати) операций;
3. O(n) - **линейная** — 10 000 (десять тысяч) операций;
4. O(n log n) - **N-логарифмическая** (например, бинарный поиск) — ~13 (чуть более тринадцати) операций;
5. O(n^2) - **квадратичная** — 100 000 000 (сто миллионов) операций;
6. O(n^3) - O(n^3), **кубическая** (если бы у нас был тройной вложенный цикл) — 1 000 000 000 000 (один триллион) операций;
7. O(2^n) - **экспоненциальная**;
8. O(n!) - O(n!), **факториальная, факториал от числа n** (поиск всех перестановок, пример — наивное решение очень популярной задачи коммивояжера) — 10 000 000 000 000 000 000 000 000...

#### Некоторые критерии качества алгоритма, помимо асимптотики

1. Потребление памяти
2. Время на реализацию
3. Сложность поддержки
4. Возможность распараллеливания
5. Необходимая квалификация сотрудника
6. Стоимость оборудования

Полуинтервал - левая граница включительная, правая исключительная.
Массив префиксов должен быть на 1 больше, чем массив с данными.
